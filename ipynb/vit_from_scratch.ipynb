{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pandas as pd, matplotlib.pyplot as plt, numpy as np, random, timeit\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes\n",
    "RANDON_SEED = 42\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 40 \n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_CLASSES = 10\n",
    "PATCH_SIZE = 4\n",
    "IMG_SIZE = 28\n",
    "IN_CHANNELS = 1\n",
    "NUM_HEADS = 8\n",
    "DROPOUT = 1e-3\n",
    "HIDDEN_DIM = 768\n",
    "ADAM_WEIGHT_DECAY = 0\n",
    "ADAM_BETAS = (\n",
    "    0.9,\n",
    "    0.999\n",
    ")\n",
    "ACTIVATION_FN = \"gelu\"\n",
    "NUM_ENCODERS = 4\n",
    "EMBED_DIM =  (PATCH_SIZE ** 2) * IN_CHANNELS # (4^2) * 1 = 16\n",
    "NUM_PATCHS = (IMG_SIZE // PATCH_SIZE) ** 2 # 49\n",
    "\n",
    "random.seed(RANDON_SEED)\n",
    "np.random.seed(RANDON_SEED)\n",
    "torch.manual_seed(RANDON_SEED)\n",
    "torch.cuda.manual_seed(RANDON_SEED)\n",
    "torch.cuda.manual_seed_all(RANDON_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para Patching as imagens\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, embed_dim, patch_size, num_patchs, dropout, in_channels):\n",
    "        super().__init__()\n",
    "        self.patcher = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=embed_dim,\n",
    "                kernel_size=patch_size,\n",
    "                stride=patch_size,\n",
    "                \n",
    "            ),\n",
    "            nn.Flatten(2)\n",
    "        )\n",
    "        \n",
    "        # Onde fazer a classificação\n",
    "        self.cls_token = nn.Parameter(torch.randn(size = (1, in_channels, embed_dim)), requires_grad=True)\n",
    "        self.position_embeddings = nn.Parameter(torch.randn(size=(1, num_patchs+1, embed_dim)), requires_grad=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        \n",
    "        x = self.patcher(x).permute(0, 2, 1)\n",
    "        x = torch.cat([cls_token, x], dim=1)\n",
    "        x = self.position_embeddings + x\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 50, 16])\n"
     ]
    }
   ],
   "source": [
    "# Testando codagem feita\n",
    "model = PatchEmbedding(EMBED_DIM, PATCH_SIZE, NUM_PATCHS, DROPOUT, IN_CHANNELS).to(device)\n",
    "x = torch.randn(512, 1, 28, 28)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_patches,\n",
    "        img_size,\n",
    "        num_classes,\n",
    "        patch_size,\n",
    "        embed_dim,\n",
    "        num_encoders,\n",
    "        num_heads,\n",
    "        hidden_dim,\n",
    "        dropout,\n",
    "        activation,\n",
    "        in_channels,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embeddings_block = PatchEmbedding(\n",
    "            embed_dim, patch_size, num_patches, dropout, in_channels\n",
    "        )\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dropout=dropout,\n",
    "            activation=activation,\n",
    "            batch_first=True,\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.encoder_blocks = nn.TransformerEncoder(\n",
    "            encoder_layer, num_layers=num_encoders\n",
    "        )\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(normalized_shape=embed_dim),\n",
    "            nn.Linear(in_features=embed_dim, out_features=num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings_block(x)\n",
    "        x = self.encoder_blocks(x)\n",
    "        x = self.mlp_head(x[:, 0, :])  # Apply MLP on the CLS token only\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gus/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:292: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 10])\n"
     ]
    }
   ],
   "source": [
    "model = ViT(\n",
    "    NUM_PATCHS, \n",
    "    IMG_SIZE, \n",
    "    NUM_CLASSES, \n",
    "    PATCH_SIZE, \n",
    "    EMBED_DIM,\n",
    "    NUM_ENCODERS,\n",
    "    NUM_HEADS,\n",
    "    HIDDEN_DIM,\n",
    "    DROPOUT,\n",
    "    ACTIVATION_FN,\n",
    "    IN_CHANNELS\n",
    "    ).to(device)\n",
    "x = torch.rand(512, 1, 28, 28)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "test_df = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=RANDON_SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTTrainDataset(Dataset):\n",
    "    def __init__(self, images, labels, indicies) -> None:\n",
    "        super().__init__()\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.indicies = indicies\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index) -> any:\n",
    "        image = self.images[index].reshape((28, 28)).astype(np.uint8)\n",
    "        label = self.labels[index]\n",
    "        index = self.indicies[index]\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"label\": label,\n",
    "            \"index\": index\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTValDataset(Dataset):\n",
    "    def __init__(self, images, labels, indicies) -> None:\n",
    "        super().__init__()\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.indicies = indicies\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5], [0.5]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index) -> any:\n",
    "        image = self.images[index].reshape((28, 28)).astype(np.uint8)\n",
    "        label = self.labels[index]\n",
    "        index = self.indicies[index]\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return {\"image\": image, \"label\": label, \"index\": index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTSubmitDataset(Dataset):\n",
    "    def __init__(self, images, indicies) -> None:\n",
    "        super().__init__()\n",
    "        self.images = images\n",
    "        self.indicies = indicies\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5], [0.5]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index) -> any:\n",
    "        image = self.images[index].reshape((28, 28)).astype(np.uint8)\n",
    "        index = self.indicies[index]\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return {\"image\": image, \"index\": index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNISTTrainDataset(\n",
    "    train_df.iloc[:, 1:].values.astype(np.uint8),\n",
    "    train_df.iloc[:, 0].values,\n",
    "    train_df.index.values\n",
    ")\n",
    "val_dataset = MNISTValDataset(\n",
    "    val_df.iloc[:, 1:].values.astype(np.uint8),\n",
    "    val_df.iloc[:, 0].values,\n",
    "    val_df.index.values,\n",
    ")\n",
    "test_dataset = MNISTSubmitDataset(\n",
    "    test_df.values.astype(np.uint8),\n",
    "    test_df.index.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "f, axarr = plt.subplots(1, 3)\n",
    "for i in range(3):\n",
    "    axarr[i].imshow(train_dataset[i][\"image\"].squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    betas=ADAM_BETAS, \n",
    "    lr=LEARNING_RATE, \n",
    "    weight_decay=ADAM_WEIGHT_DECAY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [03:16<00:00,  2.66s/it]\n",
      "100%|██████████| 9/9 [00:03<00:00,  2.63it/s]\n",
      "  2%|▎         | 1/40 [03:20<2:10:05, 200.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH 1: 1.8097\n",
      "Validation Loss EPOCH 1: 1.6145\n",
      "Train accuracy EPOCH 1: 0.3817\n",
      "Validation accuracy EPOCH 1: 0.4843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [03:20<00:00,  2.71s/it]\n",
      "100%|██████████| 9/9 [00:03<00:00,  2.55it/s]\n",
      "  5%|▌         | 2/40 [06:44<2:08:17, 202.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH 2: 1.5716\n",
      "Validation Loss EPOCH 2: 1.4062\n",
      "Train accuracy EPOCH 2: 0.5016\n",
      "Validation accuracy EPOCH 2: 0.5883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 40/74 [01:51<01:34,  2.79s/it]\n",
      "  5%|▌         | 2/40 [08:36<2:43:25, 258.04s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, label)\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m train_running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:690\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "for epoch in tqdm(range(EPOCHS), position=0, leave=True):\n",
    "    model.train()\n",
    "    train_labels, train_preds, train_running_loss = [], [], 0\n",
    "\n",
    "    for idx, img_label in enumerate(tqdm(train_dataloader, position=0, leave=True)):\n",
    "        img = img_label[\"image\"].float().to(device)\n",
    "        label = img_label[\"label\"].type(torch.uint8).to(device)\n",
    "\n",
    "        y_pred = model(img)\n",
    "        y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "        train_labels.extend(label.cpu().detach())\n",
    "        train_preds.extend(y_pred_label.cpu().detach())\n",
    "\n",
    "        loss = criterion(y_pred, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.item()\n",
    "\n",
    "    train_loss = train_running_loss / (idx + 1)\n",
    "\n",
    "    model.eval()\n",
    "    val_labels, val_preds, val_running_loss = [], [], 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, img_label in enumerate(tqdm(val_dataloader, position=0, leave=True)):\n",
    "            img = img_label[\"image\"].float().to(device)\n",
    "            label = img_label[\"label\"].type(torch.uint8).to(device)\n",
    "\n",
    "            y_pred = model(img)\n",
    "            y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "            val_labels.extend(label.cpu().detach())\n",
    "            val_preds.extend(y_pred_label.cpu().detach())\n",
    "\n",
    "            loss = criterion(y_pred, label)\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "    val_loss = val_running_loss / (idx + 1)\n",
    "\n",
    "    print(\"-\"*30)\n",
    "    print(f\"Train Loss EPOCH {epoch + 1}: {train_loss:.4f}\")\n",
    "    print(f\"Validation Loss EPOCH {epoch + 1}: {val_loss:.4f}\")\n",
    "    print(\n",
    "        f\"Train accuracy EPOCH {epoch + 1}: {sum(1 for x, y in zip(train_preds, train_labels) if x == y) / len(train_labels):.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Validation accuracy EPOCH {epoch + 1}: {sum(1 for x, y in zip(val_preds, val_labels) if x == y) / len(val_labels):.4f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print(f\"Training Time: {stop-start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, ids, imgs = [], [], []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, sample in enumerate(tqdm(test_dataloader, position=0, leave=True)):\n",
    "        img = sample[\"image\"].to(device)\n",
    "        ids.extend([int(i) + 1 for i in sample[\"index\"]])\n",
    "\n",
    "        outputs = model(img)\n",
    "\n",
    "        imgs.extend(img.detach().cpu())\n",
    "        labels.extend([int(i) for i in torch.argmax(outputs, dim=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "f, axarr = plt.subplots(2, 3)\n",
    "counter = 0\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        axarr[i][j].imshow(imgs[counter].squeeze(), cmap=\"gray\")\n",
    "        axarr[i][j].set_title(f\"Predicted {labels[counter]}\")\n",
    "        counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
